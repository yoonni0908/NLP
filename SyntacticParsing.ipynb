{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX_rBsT48SZf",
        "outputId": "ee3c9f21-d3fc-41c3-dc97-16d5eda881e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FI5DaVzC8WsD"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "root_dir = \"/gdrive/MyDrive/NLP/week7/8-2. Syntactic Parsing\"\n",
        "sys.path.append(root_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aUvoUrN9h68",
        "outputId": "5ba9df64-3888-47e0-a870-48e16321b1e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "69cn7SBY8mfT",
        "outputId": "50efb287-589b-4258-f994-e153e12eaeb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(os.path.join(root_dir, \"SyntacticParsing.JPG\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CAHrBRTd8zqL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from transformers import ElectraPreTrainedModel, ElectraModel\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class ElectraForSequenceClassification(ElectraPreTrainedModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(ElectraForSequenceClassification, self).__init__(config)\n",
        "\n",
        "        # Electra \n",
        "        self.electra = ElectraModel(config)\n",
        "\n",
        "        #   \n",
        "        self.num_labels = config.num_labels\n",
        "        \n",
        "        self.hidden_size = config.hidden_size\n",
        "\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(self.hidden_size)\n",
        "\n",
        "        self.output_layer = nn.Linear(in_features=self.hidden_size, out_features=self.num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        outputs = self.electra(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        # electra_output : (batch_size, max_length, hidden_size)\n",
        "        electra_output = outputs[0]\n",
        "\n",
        "        # cls_vector : (batch_size, hidden_size)\n",
        "        cls_vector = electra_output[:, 0, :]\n",
        "\n",
        "        cls_vector = self.dropout(cls_vector)\n",
        "\n",
        "        cls_vector = self.layer_norm(cls_vector)\n",
        "\n",
        "        cls_vector = F.gelu(cls_vector)\n",
        "\n",
        "        # outputs : (batch_size, num_labels)\n",
        "        outputs = self.output_layer(cls_vector)\n",
        "\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Rx2fbXDp8-_5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "label2idx = {\"1\":1, \"0\":0}\n",
        "idx2label = {1:'1', 0:'0'}\n",
        "def read_data(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf8\") as infile:\n",
        "        datas = []\n",
        "        for line in infile:\n",
        "            #   \\t  \n",
        "            pieces = line.strip().split(\"#%#\")\n",
        "            stack, top, bottom, queue, label = pieces[0], pieces[1], pieces[2], pieces[3], pieces[4]\n",
        "            datas.append((stack, top, bottom, queue, label))\n",
        "    return datas\n",
        "\n",
        "\n",
        "def convert_data2feature(datas, max_length, tokenizer, label2idx):\n",
        "    input_ids_features, attention_mask_features, token_type_ids_features, label_id_features = [], [], [], []\n",
        "\n",
        "    for stack, stack_top, queue_bottom, queue, label in tqdm(datas, desc=\"convert_data2feature\"):\n",
        "        # Electra tokenizer    word piece  \n",
        "        tokenized_stack = tokenizer.tokenize(stack)\n",
        "        tokenized_stack_top = tokenizer.tokenize(stack_top)\n",
        "        tokenized_queue_bottom = tokenizer.tokenize(queue_bottom)\n",
        "        tokenized_queue = tokenizer.tokenize(queue)\n",
        "\n",
        "\n",
        "        # CLS, SEP  \n",
        "        #########################################\n",
        "\n",
        "        tokens = [tokenizer.cls_token]\n",
        "        tokens += tokenized_stack\n",
        "        tokens += [tokenizer.sep_token]\n",
        "        tokens += tokenized_stack_top\n",
        "        tokens += [tokenizer.sep_token]\n",
        "        tokens += tokenized_queue_bottom\n",
        "        tokens += [tokenizer.sep_token]\n",
        "        tokens += tokenized_queue\n",
        "        tokens += [tokenizer.sep_token]\n",
        "\n",
        "        #########################################\n",
        "        \n",
        "        # word piece  index \n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)[:max_length]\n",
        "        # padding       attention mask\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        #        token type\n",
        "        token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "        # padding \n",
        "        padding = [tokenizer._convert_token_to_id(tokenizer.pad_token)] * (max_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        attention_mask += padding\n",
        "        token_type_ids += padding\n",
        "        assert max_length == len(input_ids) == len(attention_mask) == len(token_type_ids)\n",
        "\n",
        "\n",
        "        label_id = label2idx[label]\n",
        "\n",
        "        #     \n",
        "        input_ids_features.append(input_ids)\n",
        "        attention_mask_features.append(attention_mask)\n",
        "        token_type_ids_features.append(token_type_ids)\n",
        "        label_id_features.append(label_id)\n",
        "\n",
        "    #   Tensor   \n",
        "    input_ids_features = torch.tensor(input_ids_features, dtype=torch.long)\n",
        "    attention_mask_features = torch.tensor(attention_mask_features, dtype=torch.long)\n",
        "    token_type_ids_features = torch.tensor(token_type_ids_features, dtype=torch.long)\n",
        "    label_id_features = torch.tensor(label_id_features, dtype=torch.long)\n",
        "\n",
        "    return input_ids_features, attention_mask_features, token_type_ids_features, label_id_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "fNKZZzB7AGSo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, TensorDataset, RandomSampler, SequentialSampler)\n",
        "import torch.optim as optim\n",
        "\n",
        "from transformers import ElectraPreTrainedModel, ElectraTokenizer, ElectraConfig\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train(config):\n",
        "    # Electra tokenizer  \n",
        "    electra_tokenizer = ElectraTokenizer.from_pretrained(config['pretrained_model_name_or_path'])\n",
        "\n",
        "    #     \n",
        "    train_datas = read_data(config[\"train_data_path\"])\n",
        "    test_datas = read_data(config[\"test_data_path\"])\n",
        "\n",
        "    #   \n",
        "    train_input_ids_features, train_attention_mask_features, train_token_type_ids_features, train_label_id_features = \\\n",
        "        convert_data2feature(train_datas, config[\"max_length\"], electra_tokenizer, label2idx)\n",
        "    test_input_ids_features, test_attention_mask_features, test_token_type_ids_features, test_label_id_features = \\\n",
        "        convert_data2feature(test_datas, config[\"max_length\"], electra_tokenizer, label2idx)\n",
        "\n",
        "    #   batch    DataLoader  \n",
        "    train_features = TensorDataset(train_input_ids_features, train_attention_mask_features, train_token_type_ids_features, train_label_id_features)\n",
        "    train_dataloader = DataLoader(train_features, sampler=RandomSampler(train_features), batch_size=config[\"batch_size\"])\n",
        "\n",
        "    #   batch    DataLoader  \n",
        "    test_features = TensorDataset(test_input_ids_features, test_attention_mask_features, test_token_type_ids_features, test_label_id_features)\n",
        "    test_dataloader = DataLoader(test_features, sampler=SequentialSampler(test_features), batch_size=config[\"batch_size\"])\n",
        "\n",
        "    #   Electra    \n",
        "    electra_config = ElectraConfig.from_pretrained(config['pretrained_model_name_or_path'])\n",
        "    model = ElectraForSequenceClassification.from_pretrained(config['pretrained_model_name_or_path'], config=electra_config).cuda()\n",
        "\n",
        "    # loss   \n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    #    optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "    #     \n",
        "    max_accuracy = 0\n",
        "    global_step = 0\n",
        "    for epoch in range(config[\"epoch\"]):\n",
        "        model.train()\n",
        "\n",
        "        total_loss = []\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch = tuple(t.cuda() for t in batch)\n",
        "            input_ids, attention_mask, token_type_ids, label_id = batch\n",
        "\n",
        "            #      0 \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #   \n",
        "            hypothesis = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "            # loss \n",
        "            loss = loss_func(hypothesis, label_id)\n",
        "\n",
        "            # loss       gradient \n",
        "            loss.backward()\n",
        "            #      \n",
        "            optimizer.step()\n",
        "\n",
        "            if (global_step + 1) % 10 == 0:\n",
        "                print(\"Current {} Step Loss : {}\".format(global_step+1, loss))\n",
        "            if (global_step+1) % 200 == 0:\n",
        "                electra_config.save_pretrained(save_directory=config[\"output_dir_path\"])\n",
        "                model.save_pretrained(save_directory=config[\"output_dir_path\"])\n",
        "                max_accuracy = evaluate(model, electra_tokenizer, test_dataloader, step, max_accuracy)\n",
        "            global_step += 1\n",
        "def evaluate(model, tokenizer, test_dataloader=None, global_step=0, max_accuracy=0):\n",
        "    if not test_dataloader:\n",
        "        test_datas = read_data(config[\"test_data_path\"])\n",
        "\n",
        "        #   \n",
        "        test_input_ids_features, test_attention_mask_features, test_token_type_ids_features, test_label_id_features = \\\n",
        "            convert_data2feature(test_datas, config[\"max_length\"], tokenizer, label2idx)\n",
        "\n",
        "        #   batch    DataLoader  \n",
        "        test_features = TensorDataset(test_input_ids_features, test_attention_mask_features,\n",
        "                                      test_token_type_ids_features, test_label_id_features)\n",
        "        test_dataloader = DataLoader(test_features, sampler=SequentialSampler(test_features),\n",
        "                                     batch_size=config[\"batch_size\"])\n",
        "    model.eval()\n",
        "\n",
        "    #       \n",
        "    total_hypothesis, total_labels = [], []\n",
        "    for idx, batch in enumerate(test_dataloader):\n",
        "        batch = tuple(t.cuda() for t in batch)\n",
        "        input_ids, attention_mask, token_type_ids, label_id = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            #   \n",
        "            hypothesis = model(input_ids, attention_mask, token_type_ids)\n",
        "            #   softmax argmax  \n",
        "            hypothesis = torch.argmax(hypothesis, dim=-1)\n",
        "\n",
        "        # Tensor  \n",
        "        hypothesis = hypothesis.cpu().detach().numpy().tolist()\n",
        "        label_id = label_id.cpu().detach().numpy().tolist()\n",
        "\n",
        "        total_hypothesis += hypothesis\n",
        "        total_labels += label_id\n",
        "\n",
        "        if idx < 10:\n",
        "            input_ids = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
        "            input_sequence = tokenizer.convert_tokens_to_string(input_ids[1:input_ids.index(tokenizer.pad_token)] if tokenizer.pad_token in input_ids else input_ids[1:])\n",
        "            stack, top, bottom, queue, _ = [e.strip() for e in input_sequence.split(\"[SEP]\")]\n",
        "            print(\"\\nStack : \", stack)\n",
        "            print(\"Stack Top : \", top)\n",
        "            print(\"Queue Bottom : \", bottom)\n",
        "            print(\"Queue : \", queue)\n",
        "            print(\"Prediction : \", hypothesis[0])\n",
        "            print(\"Label : \", label_id[0], '\\n\\n')\n",
        "\n",
        "    #  \n",
        "    accuracy = accuracy_score(total_labels, total_hypothesis)\n",
        "    print(\"Accuracy : {}\".format(accuracy))\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "r1YxsOgeAkKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777491a6-4798-4563-bee2-97258baae299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert_data2feature: 100%|| 229639/229639 [01:59<00:00, 1928.57it/s]\n",
            "convert_data2feature: 100%|| 25838/25838 [00:11<00:00, 2154.03it/s]\n",
            "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['layer_norm.weight', 'output_layer.weight', 'output_layer.bias', 'layer_norm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Current 5310 Step Loss : 0.07515191286802292\n",
            "Current 5320 Step Loss : 0.20909346640110016\n",
            "Current 5330 Step Loss : 0.07712429761886597\n",
            "Current 5340 Step Loss : 0.13673308491706848\n",
            "Current 5350 Step Loss : 0.04980682581663132\n",
            "Current 5360 Step Loss : 0.023983493447303772\n",
            "Current 5370 Step Loss : 0.10757334530353546\n",
            "Current 5380 Step Loss : 0.08536230027675629\n",
            "Current 5390 Step Loss : 0.03805581107735634\n",
            "Current 5400 Step Loss : 0.10823851823806763\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.94852542766468\n",
            "Current 5410 Step Loss : 0.10716991126537323\n",
            "Current 5420 Step Loss : 0.16011656820774078\n",
            "Current 5430 Step Loss : 0.11228112131357193\n",
            "Current 5440 Step Loss : 0.06361059099435806\n",
            "Current 5450 Step Loss : 0.0950513482093811\n",
            "Current 5460 Step Loss : 0.08475308120250702\n",
            "Current 5470 Step Loss : 0.10100089013576508\n",
            "Current 5480 Step Loss : 0.09504177421331406\n",
            "Current 5490 Step Loss : 0.04943383112549782\n",
            "Current 5500 Step Loss : 0.1693892925977707\n",
            "Current 5510 Step Loss : 0.047048673033714294\n",
            "Current 5520 Step Loss : 0.1455455720424652\n",
            "Current 5530 Step Loss : 0.09706135839223862\n",
            "Current 5540 Step Loss : 0.07602819800376892\n",
            "Current 5550 Step Loss : 0.1634453684091568\n",
            "Current 5560 Step Loss : 0.03568838909268379\n",
            "Current 5570 Step Loss : 0.21726499497890472\n",
            "Current 5580 Step Loss : 0.08424049615859985\n",
            "Current 5590 Step Loss : 0.09328890591859818\n",
            "Current 5600 Step Loss : 0.07686237245798111\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9505766700208994\n",
            "Current 5610 Step Loss : 0.09055036306381226\n",
            "Current 5620 Step Loss : 0.09784571826457977\n",
            "Current 5630 Step Loss : 0.17626303434371948\n",
            "Current 5640 Step Loss : 0.08708928525447845\n",
            "Current 5650 Step Loss : 0.11879739165306091\n",
            "Current 5660 Step Loss : 0.0918506532907486\n",
            "Current 5670 Step Loss : 0.08980214595794678\n",
            "Current 5680 Step Loss : 0.04119675233960152\n",
            "Current 5690 Step Loss : 0.07948260009288788\n",
            "Current 5700 Step Loss : 0.08011730760335922\n",
            "Current 5710 Step Loss : 0.10568265616893768\n",
            "Current 5720 Step Loss : 0.039315156638622284\n",
            "Current 5730 Step Loss : 0.06441906839609146\n",
            "Current 5740 Step Loss : 0.07141603529453278\n",
            "Current 5750 Step Loss : 0.04546584561467171\n",
            "Current 5760 Step Loss : 0.04943450912833214\n",
            "Current 5770 Step Loss : 0.05893789231777191\n",
            "Current 5780 Step Loss : 0.08678247779607773\n",
            "Current 5790 Step Loss : 0.04889122396707535\n",
            "Current 5800 Step Loss : 0.0574105903506279\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9486415357225791\n",
            "Current 5810 Step Loss : 0.04496990516781807\n",
            "Current 5820 Step Loss : 0.12776291370391846\n",
            "Current 5830 Step Loss : 0.11804476380348206\n",
            "Current 5840 Step Loss : 0.06555084884166718\n",
            "Current 5850 Step Loss : 0.11719793826341629\n",
            "Current 5860 Step Loss : 0.0878223180770874\n",
            "Current 5870 Step Loss : 0.30004581809043884\n",
            "Current 5880 Step Loss : 0.12279298156499863\n",
            "Current 5890 Step Loss : 0.14541713893413544\n",
            "Current 5900 Step Loss : 0.06392046064138412\n",
            "Current 5910 Step Loss : 0.11754363775253296\n",
            "Current 5920 Step Loss : 0.13649727404117584\n",
            "Current 5930 Step Loss : 0.1312227100133896\n",
            "Current 5940 Step Loss : 0.03975042328238487\n",
            "Current 5950 Step Loss : 0.2086934745311737\n",
            "Current 5960 Step Loss : 0.10313551127910614\n",
            "Current 5970 Step Loss : 0.12130230665206909\n",
            "Current 5980 Step Loss : 0.09939148277044296\n",
            "Current 5990 Step Loss : 0.059673745185136795\n",
            "Current 6000 Step Loss : 0.09176005423069\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9508862915086307\n",
            "Current 6010 Step Loss : 0.06404439359903336\n",
            "Current 6020 Step Loss : 0.19374613463878632\n",
            "Current 6030 Step Loss : 0.08927298337221146\n",
            "Current 6040 Step Loss : 0.05483774468302727\n",
            "Current 6050 Step Loss : 0.03890778496861458\n",
            "Current 6060 Step Loss : 0.01997946947813034\n",
            "Current 6070 Step Loss : 0.04691692069172859\n",
            "Current 6080 Step Loss : 0.05257481336593628\n",
            "Current 6090 Step Loss : 0.06820806860923767\n",
            "Current 6100 Step Loss : 0.07574037462472916\n",
            "Current 6110 Step Loss : 0.058324653655290604\n",
            "Current 6120 Step Loss : 0.1063842698931694\n",
            "Current 6130 Step Loss : 0.12599360942840576\n",
            "Current 6140 Step Loss : 0.04229402169585228\n",
            "Current 6150 Step Loss : 0.115125373005867\n",
            "Current 6160 Step Loss : 0.03301841393113136\n",
            "Current 6170 Step Loss : 0.10191232711076736\n",
            "Current 6180 Step Loss : 0.09427649527788162\n",
            "Current 6190 Step Loss : 0.06480149179697037\n",
            "Current 6200 Step Loss : 0.06469974666833878\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9500735351033361\n",
            "Current 6210 Step Loss : 0.039978381246328354\n",
            "Current 6220 Step Loss : 0.054036207497119904\n",
            "Current 6230 Step Loss : 0.18118883669376373\n",
            "Current 6240 Step Loss : 0.06751632690429688\n",
            "Current 6250 Step Loss : 0.1713578701019287\n",
            "Current 6260 Step Loss : 0.12161817401647568\n",
            "Current 6270 Step Loss : 0.11907374858856201\n",
            "Current 6280 Step Loss : 0.09244976192712784\n",
            "Current 6290 Step Loss : 0.09392716735601425\n",
            "Current 6300 Step Loss : 0.09982096403837204\n",
            "Current 6310 Step Loss : 0.04319686070084572\n",
            "Current 6320 Step Loss : 0.07519061863422394\n",
            "Current 6330 Step Loss : 0.1310834139585495\n",
            "Current 6340 Step Loss : 0.08880070596933365\n",
            "Current 6350 Step Loss : 0.014346874319016933\n",
            "Current 6360 Step Loss : 0.011387849226593971\n",
            "Current 6370 Step Loss : 0.09796807914972305\n",
            "Current 6380 Step Loss : 0.04213174059987068\n",
            "Current 6390 Step Loss : 0.14784188568592072\n",
            "Current 6400 Step Loss : 0.0842282697558403\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9510023995665299\n",
            "Current 6410 Step Loss : 0.05471940338611603\n",
            "Current 6420 Step Loss : 0.08492308109998703\n",
            "Current 6430 Step Loss : 0.08135481178760529\n",
            "Current 6440 Step Loss : 0.09989108145236969\n",
            "Current 6450 Step Loss : 0.10447747260332108\n",
            "Current 6460 Step Loss : 0.0603955052793026\n",
            "Current 6470 Step Loss : 0.13404792547225952\n",
            "Current 6480 Step Loss : 0.09211795032024384\n",
            "Current 6490 Step Loss : 0.040130823850631714\n",
            "Current 6500 Step Loss : 0.16966183483600616\n",
            "Current 6510 Step Loss : 0.1636621505022049\n",
            "Current 6520 Step Loss : 0.15067531168460846\n",
            "Current 6530 Step Loss : 0.10669192671775818\n",
            "Current 6540 Step Loss : 0.1489766240119934\n",
            "Current 6550 Step Loss : 0.021010367199778557\n",
            "Current 6560 Step Loss : 0.06461383402347565\n",
            "Current 6570 Step Loss : 0.05231987684965134\n",
            "Current 6580 Step Loss : 0.10504940897226334\n",
            "Current 6590 Step Loss : 0.09900404512882233\n",
            "Current 6600 Step Loss : 0.05154599994421005\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  0\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9510798049384628\n",
            "Current 6610 Step Loss : 0.07212640345096588\n",
            "Current 6620 Step Loss : 0.08159162849187851\n",
            "Current 6630 Step Loss : 0.07017917186021805\n",
            "Current 6640 Step Loss : 0.09676731377840042\n",
            "Current 6650 Step Loss : 0.08480363339185715\n",
            "Current 6660 Step Loss : 0.07566704601049423\n",
            "Current 6670 Step Loss : 0.13553361594676971\n",
            "Current 6680 Step Loss : 0.1982739418745041\n",
            "Current 6690 Step Loss : 0.1687813103199005\n",
            "Current 6700 Step Loss : 0.06981796771287918\n",
            "Current 6710 Step Loss : 0.042894478887319565\n",
            "Current 6720 Step Loss : 0.1559445858001709\n",
            "Current 6730 Step Loss : 0.056844018399715424\n",
            "Current 6740 Step Loss : 0.17165355384349823\n",
            "Current 6750 Step Loss : 0.026401806622743607\n",
            "Current 6760 Step Loss : 0.09507133811712265\n",
            "Current 6770 Step Loss : 0.1040707677602768\n",
            "Current 6780 Step Loss : 0.09511399269104004\n",
            "Current 6790 Step Loss : 0.05748909339308739\n",
            "Current 6800 Step Loss : 0.05478154122829437\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9522021828314885\n",
            "Current 6810 Step Loss : 0.047670211642980576\n",
            "Current 6820 Step Loss : 0.10340511798858643\n",
            "Current 6830 Step Loss : 0.07823513448238373\n",
            "Current 6840 Step Loss : 0.09031932055950165\n",
            "Current 6850 Step Loss : 0.12752670049667358\n",
            "Current 6860 Step Loss : 0.044518474489450455\n",
            "Current 6870 Step Loss : 0.05601346492767334\n",
            "Current 6880 Step Loss : 0.0460207462310791\n",
            "Current 6890 Step Loss : 0.11966761201620102\n",
            "Current 6900 Step Loss : 0.0967482328414917\n",
            "Current 6910 Step Loss : 0.06800495833158493\n",
            "Current 6920 Step Loss : 0.13591986894607544\n",
            "Current 6930 Step Loss : 0.15543541312217712\n",
            "Current 6940 Step Loss : 0.13352017104625702\n",
            "Current 6950 Step Loss : 0.07030409574508667\n",
            "Current 6960 Step Loss : 0.05462111160159111\n",
            "Current 6970 Step Loss : 0.05144326016306877\n",
            "Current 6980 Step Loss : 0.04133724793791771\n",
            "Current 6990 Step Loss : 0.07424577325582504\n",
            "Current 7000 Step Loss : 0.049389809370040894\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9513120210542612\n",
            "Current 7010 Step Loss : 0.10314154624938965\n",
            "Current 7020 Step Loss : 0.04619334265589714\n",
            "Current 7030 Step Loss : 0.08748101443052292\n",
            "Current 7040 Step Loss : 0.1350741982460022\n",
            "Current 7050 Step Loss : 0.07127625495195389\n",
            "Current 7060 Step Loss : 0.05855156108736992\n",
            "Current 7070 Step Loss : 0.11021596193313599\n",
            "Current 7080 Step Loss : 0.1606513261795044\n",
            "Current 7090 Step Loss : 0.0447918176651001\n",
            "Current 7100 Step Loss : 0.05939161032438278\n",
            "Current 7110 Step Loss : 0.07784466445446014\n",
            "Current 7120 Step Loss : 0.07222368568181992\n",
            "Current 7130 Step Loss : 0.045381441712379456\n",
            "Current 7140 Step Loss : 0.08511369675397873\n",
            "Current 7150 Step Loss : 0.14755727350711823\n",
            "Current 7160 Step Loss : 0.03639256954193115\n",
            "Current 7170 Step Loss : 0.11546266824007034\n",
            "Current 7180 Step Loss : 0.3274858593940735\n",
            "Current 7190 Step Loss : 0.19198378920555115\n",
            "Current 7200 Step Loss : 0.31302306056022644\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9513120210542612\n",
            "Current 7210 Step Loss : 0.07354117184877396\n",
            "Current 7220 Step Loss : 0.08619530498981476\n",
            "Current 7230 Step Loss : 0.03409043326973915\n",
            "Current 7240 Step Loss : 0.019945651292800903\n",
            "Current 7250 Step Loss : 0.010892930440604687\n",
            "Current 7260 Step Loss : 0.0760323628783226\n",
            "Current 7270 Step Loss : 0.04429694265127182\n",
            "Current 7280 Step Loss : 0.08989227563142776\n",
            "Current 7290 Step Loss : 0.09657217562198639\n",
            "Current 7300 Step Loss : 0.0223369337618351\n",
            "Current 7310 Step Loss : 0.07304272800683975\n",
            "Current 7320 Step Loss : 0.058203671127557755\n",
            "Current 7330 Step Loss : 0.03599973022937775\n",
            "Current 7340 Step Loss : 0.014234175905585289\n",
            "Current 7350 Step Loss : 0.015916697680950165\n",
            "Current 7360 Step Loss : 0.07780743390321732\n",
            "Current 7370 Step Loss : 0.07570303231477737\n",
            "Current 7380 Step Loss : 0.030986659228801727\n",
            "Current 7390 Step Loss : 0.0696946308016777\n",
            "Current 7400 Step Loss : 0.024566462263464928\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9487576437804783\n",
            "Current 7410 Step Loss : 0.10509854555130005\n",
            "Current 7420 Step Loss : 0.023594144731760025\n",
            "Current 7430 Step Loss : 0.055826738476753235\n",
            "Current 7440 Step Loss : 0.052631866186857224\n",
            "Current 7450 Step Loss : 0.07891978323459625\n",
            "Current 7460 Step Loss : 0.03729289397597313\n",
            "Current 7470 Step Loss : 0.006541714537888765\n",
            "Current 7480 Step Loss : 0.019405579194426537\n",
            "Current 7490 Step Loss : 0.03555705025792122\n",
            "Current 7500 Step Loss : 0.052873946726322174\n",
            "Current 7510 Step Loss : 0.06397350132465363\n",
            "Current 7520 Step Loss : 0.02720838412642479\n",
            "Current 7530 Step Loss : 0.051247451454401016\n",
            "Current 7540 Step Loss : 0.02502310648560524\n",
            "Current 7550 Step Loss : 0.0680827796459198\n",
            "Current 7560 Step Loss : 0.10092788934707642\n",
            "Current 7570 Step Loss : 0.08375201374292374\n",
            "Current 7580 Step Loss : 0.005019317381083965\n",
            "Current 7590 Step Loss : 0.08926327526569366\n",
            "Current 7600 Step Loss : 0.0323597751557827\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9490672652682096\n",
            "Current 7610 Step Loss : 0.033401019871234894\n",
            "Current 7620 Step Loss : 0.044713009148836136\n",
            "Current 7630 Step Loss : 0.05622132867574692\n",
            "Current 7640 Step Loss : 0.07169913500547409\n",
            "Current 7650 Step Loss : 0.05091507360339165\n",
            "Current 7660 Step Loss : 0.0432165265083313\n",
            "Current 7670 Step Loss : 0.03763690963387489\n",
            "Current 7680 Step Loss : 0.07539874315261841\n",
            "Current 7690 Step Loss : 0.04395418241620064\n",
            "Current 7700 Step Loss : 0.08484102040529251\n",
            "Current 7710 Step Loss : 0.021235764026641846\n",
            "Current 7720 Step Loss : 0.044264424592256546\n",
            "Current 7730 Step Loss : 0.10503588616847992\n",
            "Current 7740 Step Loss : 0.10449063032865524\n",
            "Current 7750 Step Loss : 0.012546464800834656\n",
            "Current 7760 Step Loss : 0.013557993806898594\n",
            "Current 7770 Step Loss : 0.20852787792682648\n",
            "Current 7780 Step Loss : 0.12657223641872406\n",
            "Current 7790 Step Loss : 0.04718421772122383\n",
            "Current 7800 Step Loss : 0.030492065474390984\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9496478055577057\n",
            "Current 7810 Step Loss : 0.04887907952070236\n",
            "Current 7820 Step Loss : 0.08265826106071472\n",
            "Current 7830 Step Loss : 0.0628444105386734\n",
            "Current 7840 Step Loss : 0.01274655107408762\n",
            "Current 7850 Step Loss : 0.009244696237146854\n",
            "Current 7860 Step Loss : 0.06206103041768074\n",
            "Current 7870 Step Loss : 0.15878409147262573\n",
            "Current 7880 Step Loss : 0.08629942685365677\n",
            "Current 7890 Step Loss : 0.03290921077132225\n",
            "Current 7900 Step Loss : 0.038567278534173965\n",
            "Current 7910 Step Loss : 0.07477279007434845\n",
            "Current 7920 Step Loss : 0.08450882881879807\n",
            "Current 7930 Step Loss : 0.015293530188500881\n",
            "Current 7940 Step Loss : 0.031453490257263184\n",
            "Current 7950 Step Loss : 0.0413881354033947\n",
            "Current 7960 Step Loss : 0.12589307129383087\n",
            "Current 7970 Step Loss : 0.06092825531959534\n",
            "Current 7980 Step Loss : 0.0704256072640419\n",
            "Current 7990 Step Loss : 0.025282982736825943\n",
            "Current 8000 Step Loss : 0.03485146537423134\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9446938617540057\n",
            "Current 8010 Step Loss : 0.026644663885235786\n",
            "Current 8020 Step Loss : 0.08343527466058731\n",
            "Current 8030 Step Loss : 0.02815154567360878\n",
            "Current 8040 Step Loss : 0.09275732934474945\n",
            "Current 8050 Step Loss : 0.02923288755118847\n",
            "Current 8060 Step Loss : 0.12837567925453186\n",
            "Current 8070 Step Loss : 0.025258054956793785\n",
            "Current 8080 Step Loss : 0.04373764246702194\n",
            "Current 8090 Step Loss : 0.05167808383703232\n",
            "Current 8100 Step Loss : 0.08406740427017212\n",
            "Current 8110 Step Loss : 0.10667071491479874\n",
            "Current 8120 Step Loss : 0.2211928367614746\n",
            "Current 8130 Step Loss : 0.025625186040997505\n",
            "Current 8140 Step Loss : 0.035426512360572815\n",
            "Current 8150 Step Loss : 0.0431857630610466\n",
            "Current 8160 Step Loss : 0.04138639196753502\n",
            "Current 8170 Step Loss : 0.10757751017808914\n",
            "Current 8180 Step Loss : 0.023954901844263077\n",
            "Current 8190 Step Loss : 0.07813048362731934\n",
            "Current 8200 Step Loss : 0.04659024253487587\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9491446706401424\n",
            "Current 8210 Step Loss : 0.020282911136746407\n",
            "Current 8220 Step Loss : 0.06863956898450851\n",
            "Current 8230 Step Loss : 0.029622847214341164\n",
            "Current 8240 Step Loss : 0.012687698006629944\n",
            "Current 8250 Step Loss : 0.08783812075853348\n",
            "Current 8260 Step Loss : 0.06515902280807495\n",
            "Current 8270 Step Loss : 0.007664188742637634\n",
            "Current 8280 Step Loss : 0.029953332617878914\n",
            "Current 8290 Step Loss : 0.08313651382923126\n",
            "Current 8300 Step Loss : 0.035532139241695404\n",
            "Current 8310 Step Loss : 0.039345789700746536\n",
            "Current 8320 Step Loss : 0.021357078105211258\n",
            "Current 8330 Step Loss : 0.02556046098470688\n",
            "Current 8340 Step Loss : 0.039659250527620316\n",
            "Current 8350 Step Loss : 0.013621808029711246\n",
            "Current 8360 Step Loss : 0.0440400168299675\n",
            "Current 8370 Step Loss : 0.06844954937696457\n",
            "Current 8380 Step Loss : 0.10391996800899506\n",
            "Current 8390 Step Loss : 0.05810077115893364\n",
            "Current 8400 Step Loss : 0.025317704305052757\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9502670485331682\n",
            "Current 8410 Step Loss : 0.04994070902466774\n",
            "Current 8420 Step Loss : 0.06798788160085678\n",
            "Current 8430 Step Loss : 0.03097640536725521\n",
            "Current 8440 Step Loss : 0.10981690883636475\n",
            "Current 8450 Step Loss : 0.047234080731868744\n",
            "Current 8460 Step Loss : 0.046325668692588806\n",
            "Current 8470 Step Loss : 0.059079162776470184\n",
            "Current 8480 Step Loss : 0.0906096026301384\n",
            "Current 8490 Step Loss : 0.061772964894771576\n",
            "Current 8500 Step Loss : 0.048468269407749176\n",
            "Current 8510 Step Loss : 0.010684560053050518\n",
            "Current 8520 Step Loss : 0.02092289924621582\n",
            "Current 8530 Step Loss : 0.1347772479057312\n",
            "Current 8540 Step Loss : 0.07933836430311203\n",
            "Current 8550 Step Loss : 0.03628182411193848\n",
            "Current 8560 Step Loss : 0.027039311826229095\n",
            "Current 8570 Step Loss : 0.02242700383067131\n",
            "Current 8580 Step Loss : 0.01790362223982811\n",
            "Current 8590 Step Loss : 0.05449717491865158\n",
            "Current 8600 Step Loss : 0.08770671486854553\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9487189410945119\n",
            "Current 8610 Step Loss : 0.025306185707449913\n",
            "Current 8620 Step Loss : 0.16205139458179474\n",
            "Current 8630 Step Loss : 0.030470123514533043\n",
            "Current 8640 Step Loss : 0.09461499750614166\n",
            "Current 8650 Step Loss : 0.019215252250432968\n",
            "Current 8660 Step Loss : 0.08684133738279343\n",
            "Current 8670 Step Loss : 0.13522538542747498\n",
            "Current 8680 Step Loss : 0.029215561226010323\n",
            "Current 8690 Step Loss : 0.07585104554891586\n",
            "Current 8700 Step Loss : 0.07493897527456284\n",
            "Current 8710 Step Loss : 0.028508463874459267\n",
            "Current 8720 Step Loss : 0.07210377603769302\n",
            "Current 8730 Step Loss : 0.04147050902247429\n",
            "Current 8740 Step Loss : 0.07211707532405853\n",
            "Current 8750 Step Loss : 0.06423300504684448\n",
            "Current 8760 Step Loss : 0.20060715079307556\n",
            "Current 8770 Step Loss : 0.012020749971270561\n",
            "Current 8780 Step Loss : 0.06380510330200195\n",
            "Current 8790 Step Loss : 0.05280870199203491\n",
            "Current 8800 Step Loss : 0.04304177314043045\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9481384008050159\n",
            "Current 8810 Step Loss : 0.07425844669342041\n",
            "Current 8820 Step Loss : 0.07872357219457626\n",
            "Current 8830 Step Loss : 0.0728202685713768\n",
            "Current 8840 Step Loss : 0.11747555434703827\n",
            "Current 8850 Step Loss : 0.09724979847669601\n",
            "Current 8860 Step Loss : 0.019500257447361946\n",
            "Current 8870 Step Loss : 0.020083725452423096\n",
            "Current 8880 Step Loss : 0.010854379273951054\n",
            "Current 8890 Step Loss : 0.016653861850500107\n",
            "Current 8900 Step Loss : 0.03942275419831276\n",
            "Current 8910 Step Loss : 0.02203829027712345\n",
            "Current 8920 Step Loss : 0.06528535485267639\n",
            "Current 8930 Step Loss : 0.03690304234623909\n",
            "Current 8940 Step Loss : 0.06949850916862488\n",
            "Current 8950 Step Loss : 0.12912823259830475\n",
            "Current 8960 Step Loss : 0.015053377486765385\n",
            "Current 8970 Step Loss : 0.030300064012408257\n",
            "Current 8980 Step Loss : 0.029692109674215317\n",
            "Current 8990 Step Loss : 0.07780826836824417\n",
            "Current 9000 Step Loss : 0.016878725960850716\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9488350491524111\n",
            "Current 9010 Step Loss : 0.07587403059005737\n",
            "Current 9020 Step Loss : 0.015556004829704762\n",
            "Current 9030 Step Loss : 0.02472073584794998\n",
            "Current 9040 Step Loss : 0.07155072689056396\n",
            "Current 9050 Step Loss : 0.02972632832825184\n",
            "Current 9060 Step Loss : 0.09735312312841415\n",
            "Current 9070 Step Loss : 0.02359362505376339\n",
            "Current 9080 Step Loss : 0.005011001601815224\n",
            "Current 9090 Step Loss : 0.02121630497276783\n",
            "Current 9100 Step Loss : 0.014531071297824383\n",
            "Current 9110 Step Loss : 0.016249479725956917\n",
            "Current 9120 Step Loss : 0.06280074268579483\n",
            "Current 9130 Step Loss : 0.03364580497145653\n",
            "Current 9140 Step Loss : 0.22468441724777222\n",
            "Current 9150 Step Loss : 0.060876570641994476\n",
            "Current 9160 Step Loss : 0.04073278605937958\n",
            "Current 9170 Step Loss : 0.05479617416858673\n",
            "Current 9180 Step Loss : 0.0855097696185112\n",
            "Current 9190 Step Loss : 0.037307992577552795\n",
            "Current 9200 Step Loss : 0.035844381898641586\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9494155894419073\n",
            "Current 9210 Step Loss : 0.038411956280469894\n",
            "Current 9220 Step Loss : 0.02417929098010063\n",
            "Current 9230 Step Loss : 0.045420244336128235\n",
            "Current 9240 Step Loss : 0.04061620682477951\n",
            "Current 9250 Step Loss : 0.011618793942034245\n",
            "Current 9260 Step Loss : 0.05223637819290161\n",
            "Current 9270 Step Loss : 0.10964525490999222\n",
            "Current 9280 Step Loss : 0.04034170135855675\n",
            "Current 9290 Step Loss : 0.056071314960718155\n",
            "Current 9300 Step Loss : 0.017255790531635284\n",
            "Current 9310 Step Loss : 0.10565308481454849\n",
            "Current 9320 Step Loss : 0.08272423595190048\n",
            "Current 9330 Step Loss : 0.18120986223220825\n",
            "Current 9340 Step Loss : 0.025171790271997452\n",
            "Current 9350 Step Loss : 0.1032329723238945\n",
            "Current 9360 Step Loss : 0.02298588678240776\n",
            "Current 9370 Step Loss : 0.029438424855470657\n",
            "Current 9380 Step Loss : 0.05492408946156502\n",
            "Current 9390 Step Loss : 0.05071171373128891\n",
            "Current 9400 Step Loss : 0.02787097543478012\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9486415357225791\n",
            "Current 9410 Step Loss : 0.047111816704273224\n",
            "Current 9420 Step Loss : 0.01996549218893051\n",
            "Current 9430 Step Loss : 0.06826663762331009\n",
            "Current 9440 Step Loss : 0.03274155408143997\n",
            "Current 9450 Step Loss : 0.05586126074194908\n",
            "Current 9460 Step Loss : 0.11115618795156479\n",
            "Current 9470 Step Loss : 0.033924300223588943\n",
            "Current 9480 Step Loss : 0.05186012014746666\n",
            "Current 9490 Step Loss : 0.20996589958667755\n",
            "Current 9500 Step Loss : 0.014063860289752483\n",
            "Current 9510 Step Loss : 0.1081019788980484\n",
            "Current 9520 Step Loss : 0.12978659570217133\n",
            "Current 9530 Step Loss : 0.06468518823385239\n",
            "Current 9540 Step Loss : 0.1211070716381073\n",
            "Current 9550 Step Loss : 0.019844353199005127\n",
            "Current 9560 Step Loss : 0.04177217558026314\n",
            "Current 9570 Step Loss : 0.15671497583389282\n",
            "Current 9580 Step Loss : 0.015188382007181644\n",
            "Current 9590 Step Loss : 0.08420947939157486\n",
            "Current 9600 Step Loss : 0.009740043431520462\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9492220760120752\n",
            "Current 9610 Step Loss : 0.05231083929538727\n",
            "Current 9620 Step Loss : 0.024846190586686134\n",
            "Current 9630 Step Loss : 0.04463018849492073\n",
            "Current 9640 Step Loss : 0.027653967961668968\n",
            "Current 9650 Step Loss : 0.0466744564473629\n",
            "Current 9660 Step Loss : 0.031637270003557205\n",
            "Current 9670 Step Loss : 0.038558535277843475\n",
            "Current 9680 Step Loss : 0.08222891390323639\n",
            "Current 9690 Step Loss : 0.02078210562467575\n",
            "Current 9700 Step Loss : 0.04156837612390518\n",
            "Current 9710 Step Loss : 0.2035408318042755\n",
            "Current 9720 Step Loss : 0.050129543989896774\n",
            "Current 9730 Step Loss : 0.04271911829710007\n",
            "Current 9740 Step Loss : 0.08427248895168304\n",
            "Current 9750 Step Loss : 0.1087382435798645\n",
            "Current 9760 Step Loss : 0.07053086906671524\n",
            "Current 9770 Step Loss : 0.1142551526427269\n",
            "Current 9780 Step Loss : 0.046122901141643524\n",
            "Current 9790 Step Loss : 0.021105734631419182\n",
            "Current 9800 Step Loss : 0.03133576735854149\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9511185076244292\n",
            "Current 9810 Step Loss : 0.08710964024066925\n",
            "Current 9820 Step Loss : 0.03884606063365936\n",
            "Current 9830 Step Loss : 0.023115862160921097\n",
            "Current 9840 Step Loss : 0.06674288958311081\n",
            "Current 9850 Step Loss : 0.04491677135229111\n",
            "Current 9860 Step Loss : 0.019249042496085167\n",
            "Current 9870 Step Loss : 0.03669110685586929\n",
            "Current 9880 Step Loss : 0.044956084340810776\n",
            "Current 9890 Step Loss : 0.005972608458250761\n",
            "Current 9900 Step Loss : 0.10506658256053925\n",
            "Current 9910 Step Loss : 0.04374713450670242\n",
            "Current 9920 Step Loss : 0.11230890452861786\n",
            "Current 9930 Step Loss : 0.14084094762802124\n",
            "Current 9940 Step Loss : 0.06428001075983047\n",
            "Current 9950 Step Loss : 0.02660217694938183\n",
            "Current 9960 Step Loss : 0.03309179097414017\n",
            "Current 9970 Step Loss : 0.15602479875087738\n",
            "Current 9980 Step Loss : 0.13832810521125793\n",
            "Current 9990 Step Loss : 0.043895430862903595\n",
            "Current 10000 Step Loss : 0.029281364753842354\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9499187243594706\n",
            "Current 10010 Step Loss : 0.033512722700834274\n",
            "Current 10020 Step Loss : 0.04784458130598068\n",
            "Current 10030 Step Loss : 0.04594714567065239\n",
            "Current 10040 Step Loss : 0.059477727860212326\n",
            "Current 10050 Step Loss : 0.016199709847569466\n",
            "Current 10060 Step Loss : 0.05930403620004654\n",
            "Current 10070 Step Loss : 0.08145146816968918\n",
            "Current 10080 Step Loss : 0.039420511573553085\n",
            "Current 10090 Step Loss : 0.025258097797632217\n",
            "Current 10100 Step Loss : 0.11129339784383774\n",
            "Current 10110 Step Loss : 0.08929158002138138\n",
            "Current 10120 Step Loss : 0.09782981872558594\n",
            "Current 10130 Step Loss : 0.12883514165878296\n",
            "Current 10140 Step Loss : 0.08911386877298355\n",
            "Current 10150 Step Loss : 0.04970811679959297\n",
            "Current 10160 Step Loss : 0.01686803251504898\n",
            "Current 10170 Step Loss : 0.031374767422676086\n",
            "Current 10180 Step Loss : 0.17285649478435516\n",
            "Current 10190 Step Loss : 0.05249134451150894\n",
            "Current 10200 Step Loss : 0.12089566141366959\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9506153727068658\n",
            "Current 10210 Step Loss : 0.0644945427775383\n",
            "Current 10220 Step Loss : 0.015928175300359726\n",
            "Current 10230 Step Loss : 0.024420160800218582\n",
            "Current 10240 Step Loss : 0.09987691044807434\n",
            "Current 10250 Step Loss : 0.016659481450915337\n",
            "Current 10260 Step Loss : 0.007312935311347246\n",
            "Current 10270 Step Loss : 0.006131285801529884\n",
            "Current 10280 Step Loss : 0.04048273339867592\n",
            "Current 10290 Step Loss : 0.05747637897729874\n",
            "Current 10300 Step Loss : 0.15028387308120728\n",
            "Current 10310 Step Loss : 0.06018092855811119\n",
            "Current 10320 Step Loss : 0.03694910556077957\n",
            "Current 10330 Step Loss : 0.015905940905213356\n",
            "Current 10340 Step Loss : 0.011691560968756676\n",
            "Current 10350 Step Loss : 0.07793532311916351\n",
            "Current 10360 Step Loss : 0.06465034186840057\n",
            "Current 10370 Step Loss : 0.06034022569656372\n",
            "Current 10380 Step Loss : 0.11269200593233109\n",
            "Current 10390 Step Loss : 0.07681296020746231\n",
            "Current 10400 Step Loss : 0.06969040632247925\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.950344453905101\n",
            "Current 10410 Step Loss : 0.11023589223623276\n",
            "Current 10420 Step Loss : 0.02444266714155674\n",
            "Current 10430 Step Loss : 0.050049129873514175\n",
            "Current 10440 Step Loss : 0.06183004379272461\n",
            "Current 10450 Step Loss : 0.006934858858585358\n",
            "Current 10460 Step Loss : 0.07481728494167328\n",
            "Current 10470 Step Loss : 0.031809840351343155\n",
            "Current 10480 Step Loss : 0.031471118330955505\n",
            "Current 10490 Step Loss : 0.047203414142131805\n",
            "Current 10500 Step Loss : 0.02940995991230011\n",
            "Current 10510 Step Loss : 0.10207966715097427\n",
            "Current 10520 Step Loss : 0.04668404161930084\n",
            "Current 10530 Step Loss : 0.05834483727812767\n",
            "Current 10540 Step Loss : 0.02769930474460125\n",
            "Current 10550 Step Loss : 0.04925627261400223\n",
            "Current 10560 Step Loss : 0.05551334470510483\n",
            "Current 10570 Step Loss : 0.04392103850841522\n",
            "Current 10580 Step Loss : 0.08659300953149796\n",
            "Current 10590 Step Loss : 0.06654688715934753\n",
            "Current 10600 Step Loss : 0.026558198034763336\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9489511572103104\n",
            "Current 10610 Step Loss : 0.007655578199774027\n",
            "Current 10620 Step Loss : 0.24022160470485687\n",
            "Current 10630 Step Loss : 0.1410009264945984\n",
            "Current 10640 Step Loss : 0.15038427710533142\n",
            "Current 10650 Step Loss : 0.046421799808740616\n",
            "Current 10660 Step Loss : 0.04122614115476608\n",
            "Current 10670 Step Loss : 0.04416195675730705\n",
            "Current 10680 Step Loss : 0.06530898809432983\n",
            "Current 10690 Step Loss : 0.00845396053045988\n",
            "Current 10700 Step Loss : 0.011256440542638302\n",
            "Current 10710 Step Loss : 0.05299151688814163\n",
            "Current 10720 Step Loss : 0.11073311418294907\n",
            "Current 10730 Step Loss : 0.10494133830070496\n",
            "Current 10740 Step Loss : 0.042128320783376694\n",
            "Current 10750 Step Loss : 0.03638333082199097\n",
            "Current 10760 Step Loss : 0.15900512039661407\n",
            "Current 10770 Step Loss : 0.3064141571521759\n",
            "Current 10780 Step Loss : 0.32273590564727783\n",
            "Current 10790 Step Loss : 0.2510259449481964\n",
            "Current 10800 Step Loss : 0.13324245810508728\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  0\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9419459710503909\n",
            "Current 10810 Step Loss : 0.051097720861434937\n",
            "Current 10820 Step Loss : 0.030131462961435318\n",
            "Current 10830 Step Loss : 0.06709181517362595\n",
            "Current 10840 Step Loss : 0.0382930263876915\n",
            "Current 10850 Step Loss : 0.10856979340314865\n",
            "Current 10860 Step Loss : 0.010056774131953716\n",
            "Current 10870 Step Loss : 0.020706206560134888\n",
            "Current 10880 Step Loss : 0.015607768669724464\n",
            "Current 10890 Step Loss : 0.03690169379115105\n",
            "Current 10900 Step Loss : 0.0077668954618275166\n",
            "Current 10910 Step Loss : 0.0017215253319591284\n",
            "Current 10920 Step Loss : 0.04195743426680565\n",
            "Current 10930 Step Loss : 0.030093088746070862\n",
            "Current 10940 Step Loss : 0.039697933942079544\n",
            "Current 10950 Step Loss : 0.003961438313126564\n",
            "Current 10960 Step Loss : 0.015062956139445305\n",
            "Current 10970 Step Loss : 0.004302928689867258\n",
            "Current 10980 Step Loss : 0.007297159638255835\n",
            "Current 10990 Step Loss : 0.03600287437438965\n",
            "Current 11000 Step Loss : 0.05972084030508995\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.950537967334933\n",
            "Current 11010 Step Loss : 0.09144054353237152\n",
            "Current 11020 Step Loss : 0.013413434848189354\n",
            "Current 11030 Step Loss : 0.005366981495171785\n",
            "Current 11040 Step Loss : 0.004565359093248844\n",
            "Current 11050 Step Loss : 0.005143505986779928\n",
            "Current 11060 Step Loss : 0.01407371275126934\n",
            "Current 11070 Step Loss : 0.04001639783382416\n",
            "Current 11080 Step Loss : 0.0065504759550094604\n",
            "Current 11090 Step Loss : 0.013348343782126904\n",
            "Current 11100 Step Loss : 0.04479498788714409\n",
            "Current 11110 Step Loss : 0.008494257926940918\n",
            "Current 11120 Step Loss : 0.05657527223229408\n",
            "Current 11130 Step Loss : 0.013505823910236359\n",
            "Current 11140 Step Loss : 0.03953436017036438\n",
            "Current 11150 Step Loss : 0.038295477628707886\n",
            "Current 11160 Step Loss : 0.004209635313600302\n",
            "Current 11170 Step Loss : 0.02473956160247326\n",
            "Current 11180 Step Loss : 0.05519736185669899\n",
            "Current 11190 Step Loss : 0.05046170949935913\n",
            "Current 11200 Step Loss : 0.011637864634394646\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9484093196067808\n",
            "Current 11210 Step Loss : 0.01973552443087101\n",
            "Current 11220 Step Loss : 0.003994433209300041\n",
            "Current 11230 Step Loss : 0.0801691859960556\n",
            "Current 11240 Step Loss : 0.00309443986043334\n",
            "Current 11250 Step Loss : 0.0765237808227539\n",
            "Current 11260 Step Loss : 0.011839380487799644\n",
            "Current 11270 Step Loss : 0.006883523892611265\n",
            "Current 11280 Step Loss : 0.011996632441878319\n",
            "Current 11290 Step Loss : 0.09413477033376694\n",
            "Current 11300 Step Loss : 0.029058700427412987\n",
            "Current 11310 Step Loss : 0.005236367229372263\n",
            "Current 11320 Step Loss : 0.007528776302933693\n",
            "Current 11330 Step Loss : 0.07211922854185104\n",
            "Current 11340 Step Loss : 0.06145455315709114\n",
            "Current 11350 Step Loss : 0.04624995216727257\n",
            "Current 11360 Step Loss : 0.011638832278549671\n",
            "Current 11370 Step Loss : 0.025429749861359596\n",
            "Current 11380 Step Loss : 0.008155416697263718\n",
            "Current 11390 Step Loss : 0.06026964634656906\n",
            "Current 11400 Step Loss : 0.003506237408146262\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9498800216735042\n",
            "Current 11410 Step Loss : 0.03519543260335922\n",
            "Current 11420 Step Loss : 0.014025268144905567\n",
            "Current 11430 Step Loss : 0.019833603873848915\n",
            "Current 11440 Step Loss : 0.005887351930141449\n",
            "Current 11450 Step Loss : 0.0832807868719101\n",
            "Current 11460 Step Loss : 0.014929329045116901\n",
            "Current 11470 Step Loss : 0.01662108488380909\n",
            "Current 11480 Step Loss : 0.0406557135283947\n",
            "Current 11490 Step Loss : 0.003935349173843861\n",
            "Current 11500 Step Loss : 0.03013479895889759\n",
            "Current 11510 Step Loss : 0.006994845811277628\n",
            "Current 11520 Step Loss : 0.052927035838365555\n",
            "Current 11530 Step Loss : 0.06328576058149338\n",
            "Current 11540 Step Loss : 0.011954870074987411\n",
            "Current 11550 Step Loss : 0.036633629351854324\n",
            "Current 11560 Step Loss : 0.019181793555617332\n",
            "Current 11570 Step Loss : 0.03142669424414635\n",
            "Current 11580 Step Loss : 0.007457524072378874\n",
            "Current 11590 Step Loss : 0.032261647284030914\n",
            "Current 11600 Step Loss : 0.03314918279647827\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9492220760120752\n",
            "Current 11610 Step Loss : 0.13964493572711945\n",
            "Current 11620 Step Loss : 0.009964912198483944\n",
            "Current 11630 Step Loss : 0.11664197593927383\n",
            "Current 11640 Step Loss : 0.002726928098127246\n",
            "Current 11650 Step Loss : 0.009035813622176647\n",
            "Current 11660 Step Loss : 0.009744458831846714\n",
            "Current 11670 Step Loss : 0.016433753073215485\n",
            "Current 11680 Step Loss : 0.06591098010540009\n",
            "Current 11690 Step Loss : 0.06833575665950775\n",
            "Current 11700 Step Loss : 0.06435112655162811\n",
            "Current 11710 Step Loss : 0.0022397583816200495\n",
            "Current 11720 Step Loss : 0.060921721160411835\n",
            "Current 11730 Step Loss : 0.01556504424661398\n",
            "Current 11740 Step Loss : 0.10953472554683685\n",
            "Current 11750 Step Loss : 0.1872994303703308\n",
            "Current 11760 Step Loss : 0.018476778641343117\n",
            "Current 11770 Step Loss : 0.0031502903439104557\n",
            "Current 11780 Step Loss : 0.01865834929049015\n",
            "Current 11790 Step Loss : 0.0283400546759367\n",
            "Current 11800 Step Loss : 0.007336603477597237\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9479061846892174\n",
            "Current 11810 Step Loss : 0.019962260499596596\n",
            "Current 11820 Step Loss : 0.04687226191163063\n",
            "Current 11830 Step Loss : 0.0200132317841053\n",
            "Current 11840 Step Loss : 0.006707964930683374\n",
            "Current 11850 Step Loss : 0.13063634932041168\n",
            "Current 11860 Step Loss : 0.04494672268629074\n",
            "Current 11870 Step Loss : 0.04180680960416794\n",
            "Current 11880 Step Loss : 0.03245636448264122\n",
            "Current 11890 Step Loss : 0.008115204982459545\n",
            "Current 11900 Step Loss : 0.003959059249609709\n",
            "Current 11910 Step Loss : 0.0017700446769595146\n",
            "Current 11920 Step Loss : 0.0969497486948967\n",
            "Current 11930 Step Loss : 0.036960143595933914\n",
            "Current 11940 Step Loss : 0.018043221905827522\n",
            "Current 11950 Step Loss : 0.014401404187083244\n",
            "Current 11960 Step Loss : 0.030068563297390938\n",
            "Current 11970 Step Loss : 0.0362597331404686\n",
            "Current 11980 Step Loss : 0.08601405471563339\n",
            "Current 11990 Step Loss : 0.08388081938028336\n",
            "Current 12000 Step Loss : 0.05877475440502167\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9451195912996362\n",
            "Current 12010 Step Loss : 0.08501182496547699\n",
            "Current 12020 Step Loss : 0.029636090621352196\n",
            "Current 12030 Step Loss : 0.0729609951376915\n",
            "Current 12040 Step Loss : 0.012532759457826614\n",
            "Current 12050 Step Loss : 0.07104499638080597\n",
            "Current 12060 Step Loss : 0.037299059331417084\n",
            "Current 12070 Step Loss : 0.07848119735717773\n",
            "Current 12080 Step Loss : 0.09261495620012283\n",
            "Current 12090 Step Loss : 0.1976952850818634\n",
            "Current 12100 Step Loss : 0.013542911037802696\n",
            "Current 12110 Step Loss : 0.04584905132651329\n",
            "Current 12120 Step Loss : 0.036198992282152176\n",
            "Current 12130 Step Loss : 0.029338601976633072\n",
            "Current 12140 Step Loss : 0.1518876552581787\n",
            "Current 12150 Step Loss : 0.014199056662619114\n",
            "Current 12160 Step Loss : 0.049375928938388824\n",
            "Current 12170 Step Loss : 0.02729533053934574\n",
            "Current 12180 Step Loss : 0.030711311846971512\n",
            "Current 12190 Step Loss : 0.01261015422642231\n",
            "Current 12200 Step Loss : 0.046307921409606934\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9480222927471167\n",
            "Current 12210 Step Loss : 0.03692243620753288\n",
            "Current 12220 Step Loss : 0.023353347554802895\n",
            "Current 12230 Step Loss : 0.021812420338392258\n",
            "Current 12240 Step Loss : 0.013540510088205338\n",
            "Current 12250 Step Loss : 0.009701219387352467\n",
            "Current 12260 Step Loss : 0.044054239988327026\n",
            "Current 12270 Step Loss : 0.002042305190116167\n",
            "Current 12280 Step Loss : 0.017103945836424828\n",
            "Current 12290 Step Loss : 0.04013160243630409\n",
            "Current 12300 Step Loss : 0.004243642091751099\n",
            "Current 12310 Step Loss : 0.10758472234010696\n",
            "Current 12320 Step Loss : 0.030665801838040352\n",
            "Current 12330 Step Loss : 0.013221440836787224\n",
            "Current 12340 Step Loss : 0.03260438144207001\n",
            "Current 12350 Step Loss : 0.013025970198214054\n",
            "Current 12360 Step Loss : 0.09734705835580826\n",
            "Current 12370 Step Loss : 0.015604051761329174\n",
            "Current 12380 Step Loss : 0.015640176832675934\n",
            "Current 12390 Step Loss : 0.014706489630043507\n",
            "Current 12400 Step Loss : 0.033607590943574905\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9452356993575354\n",
            "Current 12410 Step Loss : 0.01744270510971546\n",
            "Current 12420 Step Loss : 0.01742459461092949\n",
            "Current 12430 Step Loss : 0.07024683803319931\n",
            "Current 12440 Step Loss : 0.007609090767800808\n",
            "Current 12450 Step Loss : 0.018809443339705467\n",
            "Current 12460 Step Loss : 0.008577889762818813\n",
            "Current 12470 Step Loss : 0.051494039595127106\n",
            "Current 12480 Step Loss : 0.003735437523573637\n",
            "Current 12490 Step Loss : 0.10062042623758316\n",
            "Current 12500 Step Loss : 0.01917910948395729\n",
            "Current 12510 Step Loss : 0.0666516125202179\n",
            "Current 12520 Step Loss : 0.0638873428106308\n",
            "Current 12530 Step Loss : 0.037326984107494354\n",
            "Current 12540 Step Loss : 0.009823222644627094\n",
            "Current 12550 Step Loss : 0.008886679075658321\n",
            "Current 12560 Step Loss : 0.07380915433168411\n",
            "Current 12570 Step Loss : 0.02795584686100483\n",
            "Current 12580 Step Loss : 0.010617617517709732\n",
            "Current 12590 Step Loss : 0.027268128469586372\n",
            "Current 12600 Step Loss : 0.006306829862296581\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9484867249787136\n",
            "Current 12610 Step Loss : 0.23461012542247772\n",
            "Current 12620 Step Loss : 0.027400020509958267\n",
            "Current 12630 Step Loss : 0.06106216087937355\n",
            "Current 12640 Step Loss : 0.08153905719518661\n",
            "Current 12650 Step Loss : 0.014681701548397541\n",
            "Current 12660 Step Loss : 0.054694514721632004\n",
            "Current 12670 Step Loss : 0.0167270265519619\n",
            "Current 12680 Step Loss : 0.07543094456195831\n",
            "Current 12690 Step Loss : 0.0058904686011374\n",
            "Current 12700 Step Loss : 0.07497938722372055\n",
            "Current 12710 Step Loss : 0.013858446851372719\n",
            "Current 12720 Step Loss : 0.01609039679169655\n",
            "Current 12730 Step Loss : 0.020644281059503555\n",
            "Current 12740 Step Loss : 0.007711360231041908\n",
            "Current 12750 Step Loss : 0.024108197540044785\n",
            "Current 12760 Step Loss : 0.060153935104608536\n",
            "Current 12770 Step Loss : 0.03471126779913902\n",
            "Current 12780 Step Loss : 0.05485110729932785\n",
            "Current 12790 Step Loss : 0.017777644097805023\n",
            "Current 12800 Step Loss : 0.09434327483177185\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9493381840699745\n",
            "Current 12810 Step Loss : 0.00890785176306963\n",
            "Current 12820 Step Loss : 0.017874499782919884\n",
            "Current 12830 Step Loss : 0.016201911494135857\n",
            "Current 12840 Step Loss : 0.005518102087080479\n",
            "Current 12850 Step Loss : 0.13568809628486633\n",
            "Current 12860 Step Loss : 0.008502062410116196\n",
            "Current 12870 Step Loss : 0.08109686523675919\n",
            "Current 12880 Step Loss : 0.05584080517292023\n",
            "Current 12890 Step Loss : 0.04311396926641464\n",
            "Current 12900 Step Loss : 0.09167841076850891\n",
            "Current 12910 Step Loss : 0.008627877570688725\n",
            "Current 12920 Step Loss : 0.04393241927027702\n",
            "Current 12930 Step Loss : 0.11187330633401871\n",
            "Current 12940 Step Loss : 0.003733157180249691\n",
            "Current 12950 Step Loss : 0.02068667858839035\n",
            "Current 12960 Step Loss : 0.035122379660606384\n",
            "Current 12970 Step Loss : 0.01799936592578888\n",
            "Current 12980 Step Loss : 0.0025711790658533573\n",
            "Current 12990 Step Loss : 0.13980282843112946\n",
            "Current 13000 Step Loss : 0.037671566009521484\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9478287793172846\n",
            "Current 13010 Step Loss : 0.008657404221594334\n",
            "Current 13020 Step Loss : 0.07309353351593018\n",
            "Current 13030 Step Loss : 0.02180214785039425\n",
            "Current 13040 Step Loss : 0.004183754324913025\n",
            "Current 13050 Step Loss : 0.020857909694314003\n",
            "Current 13060 Step Loss : 0.03968709334731102\n",
            "Current 13070 Step Loss : 0.01917499117553234\n",
            "Current 13080 Step Loss : 0.022454863414168358\n",
            "Current 13090 Step Loss : 0.015434160828590393\n",
            "Current 13100 Step Loss : 0.00860678218305111\n",
            "Current 13110 Step Loss : 0.0037744641304016113\n",
            "Current 13120 Step Loss : 0.05724116787314415\n",
            "Current 13130 Step Loss : 0.07521559298038483\n",
            "Current 13140 Step Loss : 0.02455500327050686\n",
            "Current 13150 Step Loss : 0.05508505180478096\n",
            "Current 13160 Step Loss : 0.021367015317082405\n",
            "Current 13170 Step Loss : 0.04602420702576637\n",
            "Current 13180 Step Loss : 0.11190652847290039\n",
            "Current 13190 Step Loss : 0.017706867307424545\n",
            "Current 13200 Step Loss : 0.05648805573582649\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9500348324173697\n",
            "Current 13210 Step Loss : 0.02146153151988983\n",
            "Current 13220 Step Loss : 0.02828126586973667\n",
            "Current 13230 Step Loss : 0.004826660733669996\n",
            "Current 13240 Step Loss : 0.11394324153661728\n",
            "Current 13250 Step Loss : 0.005773248616605997\n",
            "Current 13260 Step Loss : 0.01639840565621853\n",
            "Current 13270 Step Loss : 0.006808364763855934\n",
            "Current 13280 Step Loss : 0.06118972972035408\n",
            "Current 13290 Step Loss : 0.06719467043876648\n",
            "Current 13300 Step Loss : 0.14729326963424683\n",
            "Current 13310 Step Loss : 0.04000703990459442\n",
            "Current 13320 Step Loss : 0.020978912711143494\n",
            "Current 13330 Step Loss : 0.03334822133183479\n",
            "Current 13340 Step Loss : 0.06153273209929466\n",
            "Current 13350 Step Loss : 0.0753411054611206\n",
            "Current 13360 Step Loss : 0.008228620514273643\n",
            "Current 13370 Step Loss : 0.01850190758705139\n",
            "Current 13380 Step Loss : 0.03283468261361122\n",
            "Current 13390 Step Loss : 0.018329717218875885\n",
            "Current 13400 Step Loss : 0.018478889018297195\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9501122377893025\n",
            "Current 13410 Step Loss : 0.06792281568050385\n",
            "Current 13420 Step Loss : 0.009686347097158432\n",
            "Current 13430 Step Loss : 0.005085714161396027\n",
            "Current 13440 Step Loss : 0.0017305425135418773\n",
            "Current 13450 Step Loss : 0.014731058850884438\n",
            "Current 13460 Step Loss : 0.016122154891490936\n",
            "Current 13470 Step Loss : 0.010885156691074371\n",
            "Current 13480 Step Loss : 0.025521429255604744\n",
            "Current 13490 Step Loss : 0.0016213629860430956\n",
            "Current 13500 Step Loss : 0.007051777560263872\n",
            "Current 13510 Step Loss : 0.02875484712421894\n",
            "Current 13520 Step Loss : 0.032980337738990784\n",
            "Current 13530 Step Loss : 0.00905892439186573\n",
            "Current 13540 Step Loss : 0.011422515846788883\n",
            "Current 13550 Step Loss : 0.008956086821854115\n",
            "Current 13560 Step Loss : 0.021827854216098785\n",
            "Current 13570 Step Loss : 0.013989262282848358\n",
            "Current 13580 Step Loss : 0.015033838339149952\n",
            "Current 13590 Step Loss : 0.03553740307688713\n",
            "Current 13600 Step Loss : 0.0024023212026804686\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9507701834507315\n",
            "Current 13610 Step Loss : 0.09084884077310562\n",
            "Current 13620 Step Loss : 0.006210705265402794\n",
            "Current 13630 Step Loss : 0.049647003412246704\n",
            "Current 13640 Step Loss : 0.024876384064555168\n",
            "Current 13650 Step Loss : 0.006574041675776243\n",
            "Current 13660 Step Loss : 0.034413695335388184\n",
            "Current 13670 Step Loss : 0.007166650611907244\n",
            "Current 13680 Step Loss : 0.04217332601547241\n",
            "Current 13690 Step Loss : 0.015198820270597935\n",
            "Current 13700 Step Loss : 0.08429308235645294\n",
            "Current 13710 Step Loss : 0.05162590369582176\n",
            "Current 13720 Step Loss : 0.02652638591825962\n",
            "Current 13730 Step Loss : 0.02374863810837269\n",
            "Current 13740 Step Loss : 0.04129436984658241\n",
            "Current 13750 Step Loss : 0.020584505051374435\n",
            "Current 13760 Step Loss : 0.005807435605674982\n",
            "Current 13770 Step Loss : 0.02912265621125698\n",
            "Current 13780 Step Loss : 0.05171530693769455\n",
            "Current 13790 Step Loss : 0.0477481335401535\n",
            "Current 13800 Step Loss : 0.039305463433265686\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9495316974998065\n",
            "Current 13810 Step Loss : 0.06016286462545395\n",
            "Current 13820 Step Loss : 0.05506110563874245\n",
            "Current 13830 Step Loss : 0.0028648015577346087\n",
            "Current 13840 Step Loss : 0.04050639644265175\n",
            "Current 13850 Step Loss : 0.012768332846462727\n",
            "Current 13860 Step Loss : 0.017492664977908134\n",
            "Current 13870 Step Loss : 0.004379746504127979\n",
            "Current 13880 Step Loss : 0.004666825756430626\n",
            "Current 13890 Step Loss : 0.1769886016845703\n",
            "Current 13900 Step Loss : 0.020037394016981125\n",
            "Current 13910 Step Loss : 0.03382514789700508\n",
            "Current 13920 Step Loss : 0.013303362764418125\n",
            "Current 13930 Step Loss : 0.05275605991482735\n",
            "Current 13940 Step Loss : 0.03973040357232094\n",
            "Current 13950 Step Loss : 0.10134084522724152\n",
            "Current 13960 Step Loss : 0.04720020666718483\n",
            "Current 13970 Step Loss : 0.09579132497310638\n",
            "Current 13980 Step Loss : 0.01195070706307888\n",
            "Current 13990 Step Loss : 0.002791450824588537\n",
            "Current 14000 Step Loss : 0.021150978282094002\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9462806718786284\n",
            "Current 14010 Step Loss : 0.015344825573265553\n",
            "Current 14020 Step Loss : 0.006412982475012541\n",
            "Current 14030 Step Loss : 0.06472787261009216\n",
            "Current 14040 Step Loss : 0.03126706928014755\n",
            "Current 14050 Step Loss : 0.004743641242384911\n",
            "Current 14060 Step Loss : 0.03373725339770317\n",
            "Current 14070 Step Loss : 0.02579125203192234\n",
            "Current 14080 Step Loss : 0.013284452259540558\n",
            "Current 14090 Step Loss : 0.10247475653886795\n",
            "Current 14100 Step Loss : 0.12111298739910126\n",
            "Current 14110 Step Loss : 0.048761505633592606\n",
            "Current 14120 Step Loss : 0.014163346961140633\n",
            "Current 14130 Step Loss : 0.05044388771057129\n",
            "Current 14140 Step Loss : 0.007276841904968023\n",
            "Current 14150 Step Loss : 0.033316563814878464\n",
            "Current 14160 Step Loss : 0.004806146956980228\n",
            "Current 14170 Step Loss : 0.020801441743969917\n",
            "Current 14180 Step Loss : 0.0015573314158245921\n",
            "Current 14190 Step Loss : 0.04051998630166054\n",
            "Current 14200 Step Loss : 0.006136762909591198\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  11\n",
            "Queue :      3887     4064 .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :       \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :    ,   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :               .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :                      \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :        .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :    .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "\n",
            "Stack :     \n",
            "Stack Top :  \n",
            "Queue Bottom :   \n",
            "Queue :     \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      12  1 \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :  \n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :  20   18  8   \n",
            "Stack Top :  \n",
            "Queue Bottom :  \n",
            "Queue :   .\n",
            "Prediction :  1\n",
            "Label :  1 \n",
            "\n",
            "\n",
            "\n",
            "Stack :      ( ECSC )    (   ) NCSC   e   \n",
            "Stack Top :    \n",
            "Queue Bottom :  \n",
            "Queue :    3  .\n",
            "Prediction :  0\n",
            "Label :  0 \n",
            "\n",
            "\n",
            "Accuracy : 0.9474804551435869\n",
            "Current 14210 Step Loss : 0.03509484976530075\n",
            "Current 14220 Step Loss : 0.03516071289777756\n",
            "Current 14230 Step Loss : 0.0215463787317276\n",
            "Current 14240 Step Loss : 0.0812138020992279\n",
            "Current 14250 Step Loss : 0.02361810952425003\n",
            "Current 14260 Step Loss : 0.056979648768901825\n",
            "Current 14270 Step Loss : 0.045844852924346924\n",
            "Current 14280 Step Loss : 0.004438105970621109\n",
            "Current 14290 Step Loss : 0.00518806092441082\n",
            "Current 14300 Step Loss : 0.009747260250151157\n",
            "Current 14310 Step Loss : 0.01148943230509758\n",
            "Current 14320 Step Loss : 0.17621004581451416\n",
            "Current 14330 Step Loss : 0.10115504264831543\n",
            "Current 14340 Step Loss : 0.06818690896034241\n",
            "Current 14350 Step Loss : 0.035386938601732254\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, SequentialSampler, TensorDataset)\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "if (__name__ == \"__main__\"):\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    set_seed(seed=1234)\n",
        "\n",
        "    config = {\"mode\": \"train\",\n",
        "              \"train_data_path\": os.path.join(root_dir, \"train.txt\"),\n",
        "              \"test_data_path\": os.path.join(root_dir, \"test.txt\"),\n",
        "              \"output_dir_path\": output_dir,\n",
        "              \"pretrained_model_name_or_path\": \"monologg/koelectra-small-v3-discriminator\",\n",
        "              \"label_vocab_data_path\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
        "              \"num_labels\": 2,\n",
        "              \"max_length\": 250,\n",
        "              \"epoch\": 4,\n",
        "              \"batch_size\": 64,\n",
        "              }\n",
        "\n",
        "    if (config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    elif config[\"mode\"] == 'test':\n",
        "        tokenizer = ElectraTokenizer.from_pretrained(config[\"pretrained_model_name_or_path\"])\n",
        "        electra_config = ElectraConfig.from_pretrained(config[\"output_dir_path\"])\n",
        "        model = ElectraForSequenceClassification.from_pretrained(config[\"output_dir_path\"], config=electra_config).cuda()\n",
        "        evaluate(model, tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "\n",
        "   \n",
        "![image.png](data:image/png;base64,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)\n",
        " \n",
        "\n",
        "##  \n",
        "1. Layer normalization ->  layer normalization       \n",
        "\n",
        "  self.layer_norm = nn.LayerNorm(self.hidden_size)\n",
        "\n",
        "2.BERT    ->   GELU       \n",
        "\n",
        " from torch.nn import functional as F\n",
        "\n",
        "3.forward layer normalization GELU   \n",
        "\n",
        " cls_vector = self.layer_norm(cls_vector)\n",
        " \n",
        " cls_vector = F.gelu(cls_vector)\n",
        "\n",
        "4. nn.Dropout    \n"
      ],
      "metadata": {
        "id": "RKtkPmRCEJ1t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D257Phc0-5gy"
      },
      "source": [
        "#  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}